<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://opensemanticsearch.org/etl/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Open Semantic ETL toolkit for data integration, data analysis, document analysis, information extraction & data enrichment - Open Semantic Search</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Open Semantic ETL toolkit for data integration, data analysis, document analysis, information extraction \u0026 data enrichment";
        var mkdocs_page_input_path = "etl/README.md";
        var mkdocs_page_url = "/etl/";
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Open Semantic Search
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">About</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Usage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/search/">Search</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/search/operators/">Search operators</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../doc/search/#overview-and-exploration-with-facets">Interactive filters (Faceted search)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/search/fuzzy/">Fuzzy search</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/datamanagement/annotation/">Tagging and annotation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Structuring data and documents (Metadata management)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../doc/datamanagement/thesaurus/">Vocabulary and thesaurus (dictionary of names or concepts)</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../doc/datamanagement/ontologies/">Lists, Dictionaries, Vocabularies and Thesauri (Ontologies)</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Analyze and explore (Analytics)</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../investigative_journalism/howto-analyze-leaks/">Investigate massive leaks for investigative reporting</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../doc/analytics/law/">Legal codes and law clauses</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/search/list/">Search by list of names (batch searches)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Administration</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/tutorial/">Getting started</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/admin/install/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/admin/config/">Configuration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/admin/queue/">Task queue</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../doc/admin/config/log/">Logs</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Additional Applications</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="/solr-search-csv-python-django/README.md">CSV Manager</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/graph-explorer/README.md">Graph Explorer</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/lexememes/README.md">Lexememes</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/solr-ontology-tagger/README.md">Ontology Tagger</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/solr-relevance-ranking-analysis/README.md">Relevance Ranking Analysis</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/rdf2ocr/README.md">RDF or SKOS to OCR</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/rss-feed-manager-python-django/README.md">RSS-Feed Manager</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/search-list/README.md">Search Lists</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/skos2solr/README.md">SKOS to Solr</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/solr/README.md">Solr Server</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/tagger/README.md">Tagger</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="/solr-search-querytagger-python-django/README.md">QueryTagger</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../download/">Download</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="https://github.com/opensemanticsearch/open-semantic-search/">Development</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../donate/README.md">Donate</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Open Semantic Search</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Open Semantic ETL toolkit for data integration, data analysis, document analysis, information extraction & data enrichment</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/opensemanticsearch/open-semantic-search/edit/master/docs/etl/README.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="open-semantic-etl-toolkit-for-data-integration-data-analysis-document-analysis-information-extraction-data-enrichment">Open Semantic ETL toolkit for data integration, data analysis, document analysis, information extraction &amp; data enrichment</h1>
<h2 id="open-source-frameworks-for-data-integration-document-processing-information-extraction-data-analysis-merging-combining-data-content-enrichment-and-data-enrichment-pipelines">Open source frameworks for data integration, document processing, information extraction, data analysis, merging &amp; combining data, content enrichment and data enrichment pipelines</h2>
<p>Since most data is available in open standards or extractable by open source software libraries and free software, you can use different open source toolkits or frameworks to extract, transform and load (ETL) data into the search index.</p>
<p>The preconfigured <em>Open Semantic ETL</em> is a Python based lightweight, flexible, extendable, modular and interoperable free software and <strong>open source ETL (extract, transform, load), content enrichment and data enrichment framework, toolkit or data enrichment management system</strong> for <strong>document processing, automated content analysis and media analysis, information extraction, merge and data enrichment pipelines</strong> managing multiple, different and modular <strong>import, extraction, content analysis, data combining or data enrichment plugins</strong>.</p>
<p>Since the architecture of the search engine is modular, using open standards for Linked Data and Semantic Web like RDF or SKOS and the basis Elastic Search or Solr providing common standard APIs, you can use or integrate many other alternate Open Source ETL and data analysis tools instead or additionally.</p>
<h2 id="extract-structured-data-from-unstructured-documents-information-extraction-merge-and-enrich-data-with-multiple-other-data-sources-and-data-analysis-tools">Extract structured data from unstructured documents (Information extraction), merge and enrich data with multiple other data sources and data analysis tools</h2>
<p>Modular data enrichment plugins (enhancer) extract structured data from even from unstructured documents or plain text and enhance or enrich the content with additional meta data or analytics.</p>
<h2 id="document-processing-document-analysis-data-integration-content-analysis-and-data-enrichment-pipeline-enhancement-chain">Document processing, document analysis, data integration, content analysis and data enrichment pipeline (Enhancement chain)</h2>
<p>The document processing pipeline or chain is a list of data enrichment plugins (enhancer), which will be runned for each document to enrich, analyse or link them with additional data or analysis.</p>
<p>A part of the default <a href="#config">document processing pipeline configuration</a> is for example:
* Crawl a directory and its files and subdirectories
* Filter blacklists (filter_blacklist)
* Filter if file indexed yet and not modified since last indexing (filter_file_not_modified)
* Extract text (enhance_text)
* OCR images (enhance_ocr)
* Adding annotations and tags (enhance_rdf)
* Exporting or indexing to <strong>SQL or NoSQL database</strong> and/or <strong>search index</strong> (f.e. <a href="http://lucene.apache.org/solr"><em>Apache Solr</em></a> or <em><a href="elasticsearch">Elastic Search</a></em> or a <em><a href="export/rdf">Linked Data <strong>triplestore</strong> like Apache Jena Fuseki</a></em>)</p>
<h2 id="semantic-data-enrichment-plugins">Semantic data enrichment plugins</h2>
<p>Such modular data enrichment plugins (enhancer) will extract structured data from unstrucutred documents, enhance or enrich the content with additional meta data or analytics.</p>
<p>For example the <a href="../doc/datamanagement/named_entities">named entities extractor</a> or <a href="../enhance/ocr">OCR for image files</a>.</p>
<h2 id="configuration-of-a-custom-document-processing-content-analysis-and-data-enrichment-pipeline">Configuration of a custom document processing, content analysis and data enrichment pipeline</h2>
<p>If you use only Open Semantic ETL you can use <code>*/etc/etl/config*</code> to setup your data analysis and data enrichment chain and to set an db/exporter/writer where to store or index the results (for example <em>Solr</em>, <em>Elastic Search</em>, a triplestore or a database).</p>
<p>If you use the preconfigurated full search engine Open Semantic Search the pipeline or the enabled plugins are configurated for all data sources in <code>*/etc/opensemanticsearch/etl*</code> or can be overwritten or extended for each data source or connector in their specialized configs like <code>*connector-files*</code>.</p>
<p>The analysis chain runs in order, since some plugins depend on data analysis of other plugins.</p>
<p>You can add additional or new data enrichment plugins to <code>config['plugins']</code>.</p>
<p>Or you overwrite this config option to define a custom data enrichment pipeline with only a few needed plugins.</p>
<p>You can overwrite the config by parameters of the command line tools, for example to use a custom config file or to set the plugin for your data analysis and data enrichment chain.</p>
<p>So you can set a custom config file on the command line with the parameter <code>--config</code>, for example:
<code>etl-file --config */etc/etl/MyCustomConfig* *filename*</code></p>
<h2 id="usage-extract-analyze-and-enrich">Usage: Extract, analyze and enrich</h2>
<p>Extract, analyze and enrich and export data from files or webpages:</p>
<p><code>etl-file *filename*</code>
to import/extract/analyze/enrich a file</p>
<p>or</p>
<p><code>etl-file *directory*</code>
to import/extract/analyze/enrich all files of a directory and its sub directories</p>
<p>or</p>
<p><code>etl-file-monitoring *directory or file*</code>
for monitoring a directory and import/extract/analyze/enrich new or changed files</p>
<p>or</p>
<p><code>etl-web *uri*</code>
to download a file or webpage from the web and extract, analyze and enrich it</p>
<h2 id="enrich-parts-enrich-later-add-additional-enrichments-update-data-enrichments-or-distributed-data-enrichment">Enrich parts, enrich later, add additional enrichments, update data enrichments or distributed data enrichment</h2>
<p>The tool <code>etl-enrich</code> can run data enrichment parts or plugins which are not enabled in your default document processing pipe later or from time to time.</p>
<p>For example sometimes its better to index all documents without OCR in short time and after that to do the OCR of the documents with images which will need long time. So the users are able to search in most documents and text, not having to wait until only few parts and only for a few documents like some text in images are recognized in a long time process first before other documents after them were indexed, which takes only very few time, because there are no images.</p>
<p>Or you can do expensive data enrichment like OCR at night or on low server load or distribute this work on different processors (parallel processing) or servers (cluster) or web services (cloud).</p>
<p>Another possibility is to enrich with tools or webservices that imporoved or updated their results because of better analytics quality or more available data from time to time to integrate newer data or analytcs results.</p>
<p>Or to enrich later with a additional webservice, without to have to run the full document processing chain again.</p>
<p>Or if a webservice was not available while indexing to enrich data with its analytics later.</p>
<h3 id="run-additional-data-analysis-or-data-enrichment-plugins">Run additional data analysis or data enrichment plugins</h3>
<p>You can run the tool from REST-API or on the command line:
<code>etl-enrich --plugins *pluginname*</code></p>
<p>Optional you can add a search or filter query, so only the interesting or important data or document(s) will get enriched:
<code>etl-enrich --plugins *pluginname* --query *query*</code></p>
<h2 id="enrichment-with-results-of-webservices-and-apis">Enrichment with results of webservices and APIs</h2>
<p>You can analyze your data with internal webservices (or if you dont need privacy with external webservices or "the cloud") and read the results with the standard RDF enhancer plugin.</p>
<p>If the webservice results are not in standard Semantic Web formats, but only an API, you can call the API and read the results in your favorite programming language in a custom data enrichment plugin:</p>
<h2 id="development-of-own-data-enrichment-plugins">Development of own data enrichment plugins</h2>
<p>You can develop own data enrichment plugins with few lines of code using the data enrichment interfaces for Python plugins, Javascript plugins or Java Plugins.</p>
<p>Or you develop or use a webservice in your favorite programming language and read its results with the standard RDF enhancer plugin.</p>
<p><a href="../dev/enhancer">Learn more about development of data enrichment plugins</a> ...</p>
<h2 id="scale-for-big-data-analysis">Scale for big data analysis</h2>
<p>If there is big data and you have to index faster, you can <a href="../doc/admin/scale">scale by parallel processing, search clusters and optimizing RAM settings</a>.</p>
<h2 id="other-frameworks-for-data-integration-for-data-warehouse-or-for-extraction-transformation-and-load-etl-or-data-enrichment">Other frameworks for data integration for data warehouse or for extraction, transformation and load (ETL) or data enrichment</h2>
<p>There are powerful open source ETL frameworks (extraction, transformation and load) for data integration, mapping, filtering and transformation for data warehousing with powerful features and graphical user interfaces (GUI).</p>
<p><img alt="" src="../screenshots/spoon_job.png" />
<img alt="" src="../screenshots/spoon_transformation.png" /></p>
<p>If there is an output plugin for Solr or if the tools can export data in a format which can be imported by one of our <a href="../doc/admin/connectors">connectors (crawler, extraction or input plugin)</a>, you can use this open source frameworks like <a href="http://community.pentaho.com/projects/data-integration/">Kettle</a> or <a href="https://www.talend.com/resource/etl-tool.html">Talend Open Studio</a> to integrate, extract, transform, enrich and load (index) data to the search engine.</p>
<h2 id="other-data-enrichment-frameworks-based-on-semantic-web-standards">Other data enrichment frameworks based on Semantic Web standards</h2>
<p>You can use the <a href="http://stanbol.apache.org/docs/trunk/components/enhancer/">Apache Stanbol</a> data enrichment framework and one or more of its many <a href="http://stanbol.apache.org/docs/trunk/components/enhancer/engines/list">enhancer engines</a>.</p>
<h2 id="transform-unstructured-documents-to-semantic-linked-data">Transform unstructured documents to semantic linked data</h2>
<p>There are not only output/storage/index writer/exporter plugins for search engines like Solr or Elastic Search, but for triplestores, too:</p>
<p>So with its <a href="export/solr2rdf">triplestore storage or output plugins for RDF export</a> it can integrate unstructured data like document files and document analysis like OCR to <a href="#semanticweb">structured Linked Data like RDF graphs and with Semantic Web Tools like a triplestore</a> and many other tools working with <a href="#semanticweb">open standards for the Semantic Web</a>.</p>
<p>So it can not only be used for data analysis, data enrichment and merging but as a converter from more or less unstructured document files to linked data like PDF to RDF, Word to RDF, DOC to RDF, OCR to RDF, JPG to RDF, PNG to RDF or as flexible importer for Semantic Web infrastructure like triplestores, too.</p>
<p>Or it can be seen as an Semantic Web-API for legacy files, documents or command line data analysis tools serving their data or analysis results to Semantic Web infrastructure.</p>
<p>Another Framework for getting Semantic Web or Linked Data graphs with structured data from unstructured or legacy files are:
* <a href="http://etl.linkedpipes.com/">Linked Pipes ETL</a>: RDF based open source framework for extract transform load (Java)
* <a href="http://ldif.wbsg.de/">LDIF</a>: linked data integration framework
* <a href="http://usc-isi-i2.github.io/karma/">Karma</a>: Data integration tool
* <a href="http://silkframework.org/">Silk</a>: open source framework for integrating heterogeneous data sources
* <a href="http://stanbol.apache.org/docs/trunk/components/enhancer/">Apache Stanbol</a>: Data enrichment framework reads text and serves a RDF graph</p>
<h2 id="linked-data-and-semantic-web">Linked Data and Semantic Web</h2>
<p>Linked Data (LD) or Semantic Web (Web 3.0) and <a href="../doc/datamanagement/opendata">Linked Open Data (LOD)</a> based on standard formats like RDF, JSON-LD or Turtle makes data integration, data enrichment and merging data sources easier. Parts of such databases or graphs can be queried and filtered via the query language SPARQL.</p>
<p>The data is available in open standard linked data formats and can be imported to your favorite formats and accessable with your favorite tools, software or library.</p>
<h2 id="merging-multiple-data-sources-to-one-graph-database">Merging multiple data sources to one graph database</h2>
<p>To merge data from different semantic web sources, just load their graphs (database with linked data) into the triplestore (database server) and match or map the properties (in traditional databases this would be columns or data fields).</p>
<p>Your triple store or frameworks like for example OpenRDF bring some tools to load linked data in RDF or Turtle format into the triplestore.</p>
<p>To download and import external graph databases or external linked data, you can use Semantic Web ETL frameworks:
* <a href="https://github.com/UnifiedViews">Unified Views</a>: ETL tool for RDF data</p>
<h2 id="merging-data-fields-of-different-data-sources-and-ids-entity-mapping">Merging data fields of different data sources and IDs (Entity Mapping)</h2>
<p>If the different data sources don't use a common standard for data fields or IDs like Dublin Core or <a href="../doc/datamanagement/opendata">Wikidata</a>:</p>
<p>To merge, connect and map the data fields of different data sources, you can add another graph: an ontology for mapping/connecting different property names or IDs. With the property "Same as" you can map or merge different data sources to one graph.</p>
<h3 id="tools-and-methods">Tools and Methods</h3>
<ul>
<li>Semantic Web: Entity Mapping with properties like <em>Same As</em> or <a href="../doc/datamanagement/thesaurus">linking different relations of concepts with Simple Knowledge Organisation System (<em>SKOS</em>)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Record_linkage">Record linkage</a> (for example with Joins: <a href="https://wiki.apache.org/solr/Join">Solr Join</a> or <a href="https://en.wikipedia.org/wiki/Join_%28SQL%29">SQL Join</a> (if same keys or ids in both datasets) and/or Leavensthein distance for similarity</li>
<li>Open Refine reconcile API</li>
</ul>
<h2 id="open-data-sources-data-enrichment-with-linked-open-data">Open Data sources: Data enrichment with Linked Open Data</h2>
<p>Since there is many open data in this open standard formats for linked data, you can enrich your data with many <a href="../doc/datamanagement/opendata">free knowledge bases like WikiData or DBPedia (the structured database of Wikipedia)</a>, which is available via a SPARQL Endpoint.</p>
<h2 id="other-open-source-projects">Other open source projects</h2>
<ul>
<li><a href="http://tika.apache.org/">Tika</a>: Content Analysis Toolkit: extracts content and meta data like author and from different document and file formats</li>
<li><a href="http://manifoldcf.apache.org/">Apache ManifoldCF</a>: Data integration framework reads different datasources and export to index</li>
<li><a href="http://uima.apache.org/">Apache UIMA</a> - Pipelines to get strucutred information out of unstructured documents or data</li>
<li><a href="https://github.com/dkpro/dkpro-core">DKPro Core</a>: Provides UIMA components wrapping natural language processing (NLP) tools so they can be used interchangeably in UIMA processing pipelines</li>
<li><a href="http://kitesdk.org/docs/current/morphlines/">Kite morphlines</a>: ETL framework to import data to Solr or Hadoop</li>
<li><a href="https://flume.apache.org/">Apache Flume</a>: Framework for data pipes</li>
<li><a href="http://community.pentaho.com/projects/data-integration/">Kettle</a>: ETL framework with GUI</li>
<li><a href="https://www.talend.com/resource/etl-tool.html">Talend Open Studio</a>: ETL framework with GUI</li>
<li><a href="https://nifi.apache.org/">Apache NiFi</a>: Automated and managed flow and transformation of information between systems</li>
<li><a href="http://www.dswarm.org">DSWARM</a>: Data management platform for enrichment, normalization and linkage of knowledge data structures</li>
<li><a href="https://github.com/europeana">Europeana Code repository</a>: ETL tools for Europeana library</li>
<li><a href="http://www.scrapy.org">Scrapy</a>: Crawler and data extractor for extracting structured data from websites not providing an API for getting JSON or linked data like RDF but for example HTML without semantic annotations like RDFa</li>
<li>MapReduceIndexerTool: Indexing many files to Solr faster using an Hadoop cluster (MapReduce is used for parallel processing on a cluster)</li>
<li><a href="http://www.freme-project.eu/">Freme Project</a>: Open framework for multilingual and semantic enrichment of digital content</li>
</ul>
<h2 id="methods">Methods</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Data_integration">Data integration</a></li>
<li><a href="https://en.wikipedia.org/wiki/Extract,_transform,_load">Extract, transform, load (ETL)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Optical_character_recognition">Optical character recognition (OCR)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Information_extraction">Information extraction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Entity_linking">Entity Linking</a></li>
<li><a href="https://en.wikipedia.org/wiki/Web_crawler">Crawling</a></li>
<li><a href="https://en.wikipedia.org/wiki/Document_processing">Document processing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Document_automation">Document automation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Document_modelling">Document modelling</a></li>
</ul>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/opensemanticsearch/open-semantic-search/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
